{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69900d4",
   "metadata": {},
   "source": [
    "用torch搭建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8937a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyDenseLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(input_dim, output_dim), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.randn(1, output_dim), requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z = torch.matmul(inputs, self.W) + self.b\n",
    "        output = torch.sigmoid(z)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337cc319",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "n = 20\n",
    "layer = nn.Linear(in_features = m, out_features=2) # dense layer without activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(m,n),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(m,2)\n",
    ") # 一层层叠加构成网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.functional.cross_entropy(predicted, y) # binary\n",
    "loss = torch.nn.functional.mse_loss(predicted, y) # continuous number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive learning rate\n",
    "torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # stochastic gradient descent\n",
    "torch.optim.Adam(model.parameters(), lr=0.001) # Adam optimizer\n",
    "torch.optim.Adadelta(model.parameters(), lr=0.001) # Adadelta optimizer\n",
    "torch.optim.Adagrad(model.parameters(), lr=0.01) # Adagrad optimizer\n",
    "torch.optim.RMSprop(model.parameters(), lr=0.01) # RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop out\n",
    "torch.nn.Dropout(p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa01b6",
   "metadata": {},
   "source": [
    "用tensorflow搭建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7cc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MyDenseLayer1(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyDenseLayer1, self).__init__()\n",
    "\n",
    "        self.W = self.add_weight([input_dim, output_dim])\n",
    "        self.b = self.add_weight([1,output_dim])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z = tf.matmul(inputs, self.W) + self.b\n",
    "        output = tf.math.sigmoid(z)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d455fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(units = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f150d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(n, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd302c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, predicted))\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(y, predicted)))  # continuous number\n",
    "loss = tf.keras.losses.MSE(y, predicted)  # continuous number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.3\n",
    "\n",
    "def compute_loss(weights):\n",
    "    # Dummy loss function for demonstration\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, predicted))\n",
    "\n",
    "weights = tf.Variable([tf.random.normal()]) # 可以更新的张量\n",
    "while True:\n",
    "    with tf.GradientTape() as g: # 上下文管理器，用于监听参数的变化\n",
    "        loss = compute_loss(weights)\n",
    "        gradients = g.gradient(loss, weights)\n",
    "    weights = weights - lr * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ecdd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive learning rate\n",
    "tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)  # stochastic gradient descent\n",
    "tf.keras.optimizers.Adam(learning_rate=0.001)  # Adam optimizer\n",
    "tf.keras.optimizers.Adadelta(learning_rate=0.001)  # Adadelta optimizer\n",
    "tf.keras.optimizers.Adagrad(learning_rate=0.01)  # Adagrad optimizer\n",
    "tf.keras.optimizers.RMSprop(learning_rate=0.01)  # RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it all together\n",
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential([])\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "while True:\n",
    "    prediction(x)\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(y, prediction)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout\n",
    "tf.keras.layers.Dropout(p=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
