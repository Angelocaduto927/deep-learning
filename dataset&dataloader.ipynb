{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f9d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68558832",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([[1,2],\n",
    "                       [3,4],\n",
    "                       [5,6],\n",
    "                       [7,8]])\n",
    "y_train = torch.tensor([0, 1, 0, 1])\n",
    "x_test = torch.tensor([[9,10],\n",
    "                      [11,12],\n",
    "                      [13,14],\n",
    "                      [15,16]])\n",
    "y_test = torch.tensor([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eebe2d",
   "metadata": {},
   "source": [
    "传入数据的类型可以是  \n",
    "- `torch.Tensor`（如：`x_train`, `y_train`, `x_test`, `y_test`）  \n",
    "- 自定义的 `Dataset` 类（如：`train_dataset`, `test_dataset`，对应变量 `tr`, `te`）\n",
    "\n",
    "对于自定义的 `Dataset` 类，传入的数据不一定非要是 `torch.Tensor`，也可以是 `numpy.ndarray`、`list` 等类型。只要在 `__getitem__` 方法中能够正确处理这些数据类型即可。不过，为了与 PyTorch 的训练流程兼容，通常推荐使用 `torch.Tensor`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class train_dataset(Dataset):\n",
    "    def __init__(self, x, y, transform=True):\n",
    "        self.feature = x\n",
    "        self.label = y\n",
    "        if transform:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,))\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.feature[idx], self.label[idx]\n",
    "    #   return self.transform(self.feature[idx]), self.label[idx]\n",
    "\n",
    "class test_dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.feature = x\n",
    "        self.label = y\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    def __getitem__(self, idx):\n",
    "        return {'feature': self.feature[idx],\n",
    "                'label': self.label[idx]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d6f32",
   "metadata": {},
   "source": [
    "构建自定义数据类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef65438",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = train_dataset(x_train, y_train, transform=True)\n",
    "te = test_dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a64249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.__len__()  # Should return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60eecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Features: tensor([[5, 6],\n",
      "        [3, 4]])\n",
      "Labels: tensor([0, 1])\n",
      "Batch 2:\n",
      "Features: tensor([[7, 8],\n",
      "        [1, 2]])\n",
      "Labels: tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(0) # For reproducibility\n",
    "train_loader = DataLoader(tr, batch_size=2, shuffle=True,num_workers=0, drop_last=True)\n",
    "test_loader = DataLoader(te, batch_size=2, shuffle=False,num_workers=0)\n",
    "for idx,(x,y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\")\n",
    "    print(\"Features:\", x)\n",
    "    print(\"Labels:\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ee027",
   "metadata": {},
   "source": [
    "将实例化的数据集传入dataloader  \n",
    "如果样本数不能被batch整除，加上drop_last，否则最后多出来的样本会有更大的权重不平衡  \n",
    "`num_workers` 参数用于设置加载数据时使用的子进程数量，可以加速数据的读取。它不是用来分配内存的，而是通过多进程并行预取数据，提高数据加载效率。比如worker为0时，只有一个进程他需要训练一组数据，然后在加载另一组数据，中间就会花费一些时间，但是如果有两个worker，就可以一个在训练另一个同步加载数据，节省时间。\n",
    "\n",
    "worker数量增加的代价主要有：  \n",
    "- 占用更多的CPU资源，可能导致系统资源紧张，影响其他进程  \n",
    "- 每个worker进程都需要初始化，会有一定的启动开销  \n",
    "- 数据加载过程中，主进程和worker进程之间需要进行数据的通信（如通过队列传递），这会带来一定的内存和带宽消耗  \n",
    "- 如果数据预处理很轻量，worker过多反而可能导致效率下降（进程切换、通信开销大于实际加速效果）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the fly data loading (more efficient)\n",
    "import os\n",
    "from PIL import Image\n",
    "class largeimage_dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(root_dir) # return list of files in the directory\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB') # get image here, one by one\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
